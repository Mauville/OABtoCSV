{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc13eeb-473a-4087-890b-de327a75a987",
   "metadata": {},
   "source": [
    "# OAB to CSV\n",
    "Convert the mythical OAB format into a CSV.\n",
    "Note that the conversion is a bit scuffed, leaving some fields raw, and some as bits.\n",
    "\n",
    "This should help you open the file and extract the information that you want, but is in no way an exhaustive solution.\n",
    "\n",
    "Just drop your `udetails.oab` file in the root of this notebook.\n",
    "\n",
    "OAB Parser code from:\n",
    "https://github.com/byteDJINN/BOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29a787-1db3-4eda-ab66-3b21a7dcd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack, error\n",
    "from io import BytesIO\n",
    "import math\n",
    "import binascii\n",
    "from schema import PidTagSchema\n",
    "import json\n",
    "import re \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9d2fd-a3cc-4c67-90d3-2fd7392f5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the table of tags and codes\n",
    "def hexify(PropID):\n",
    "  return \"{0:#0{1}x}\".format(PropID, 10).upper()[2:]\n",
    "\n",
    "def lookup(ulPropID):\n",
    "  if hexify(ulPropID) in PidTagSchema:\n",
    "    (PropertyName, PropertyType) = PidTagSchema[hexify(ulPropID)]\n",
    "    return PropertyName\n",
    "  else:\n",
    "    return hex(ulPropID)\n",
    "# Originally, this script used to just ouput the DisplayName of each entry. \n",
    "# It was stored on this variable\n",
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f284474-748a-40c3-bf09-09079ff6f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading a binary file, always add a 'b' to the file open mode\n",
    "with open('udetails.oab', 'rb') as f:\n",
    "  ###############\n",
    "  # BEGIN MAGIC #\n",
    "  ###############\n",
    "  (ulVersion, ulSerial, ulTotRecs) = unpack('<III', f.read(4 * 3))\n",
    "  assert ulVersion == 32, 'This only supports OAB Version 4 Details File'\n",
    "  print(\"Total Record Count: \", ulTotRecs)\n",
    "  # OAB_META_DATA\n",
    "  cbSize = unpack('<I', f.read(4))[0]\n",
    "  # print \"OAB_META_DATA\",\n",
    "  meta = BytesIO(f.read(cbSize - 4))\n",
    "  # the length of the header attributes\n",
    "  # we don't know and don't really need to know how to parse these\n",
    "  HDR_cAtts = unpack('<I', meta.read(4))[0]\n",
    "  print(\"rgHdrAtt HDR_cAtts\",HDR_cAtts)\n",
    "  for rgProp in range(HDR_cAtts):\n",
    "    ulPropID = unpack('<I', meta.read(4))[0]\n",
    "    ulFlags  = unpack('<I', meta.read(4))[0]\n",
    "    # print rgProp, lookup(ulPropID), ulFlags\n",
    "  # these are the attributes that we actually care about\n",
    "  OAB_cAtts = unpack('<I', meta.read(4))[0]\n",
    "  OAB_Atts = []\n",
    "  print(\"rgOabAtts OAB_cAtts\", OAB_cAtts)\n",
    "  for rgProp in range(OAB_cAtts):\n",
    "    ulPropID = unpack('<I', meta.read(4))[0]\n",
    "    ulFlags  = unpack('<I', meta.read(4))[0]\n",
    "    # print rgProp, lookup(ulPropID), ulFlags\n",
    "    OAB_Atts.append(ulPropID)\n",
    "  print(\"Actual Count\", len(OAB_Atts))\n",
    "  # OAB_V4_REC (Header Properties)\n",
    "  cbSize = unpack('<I', f.read(4))[0]\n",
    "  f.read(cbSize - 4)\n",
    "  ###############\n",
    "  #  END  MAGIC #\n",
    "  ###############\n",
    "\n",
    "  # Stores users that have all their data intact and with no read errors.\n",
    "  users = []\n",
    "  # Stores users that errored out on reading. \n",
    "  # On my side, they were virtually the same as the normal ones, and I don't know enough bitmanip to know why.\n",
    "  # You should probably double check they're ok with your .oab file\n",
    "  broken_users = []\n",
    "\n",
    "  error_count = 0\n",
    "  seen_emails = set()\n",
    "\n",
    "  # Although the number 900000 might sound like magic, from what I can gather from the original script, \n",
    "  # it's just a placeholder that kind of represents the amount of records on the file. If you make it too high, the script used to \n",
    "  # start duplicating the last entry until it got to the end. I've removed this edge case, so feel free to put it as high as you want.\n",
    "  for counter in tqdm(range(900000)):\n",
    "    try:\n",
    "      read = f.read(4)\n",
    "      if read == '':\n",
    "        print(f\"Stopped at {counter}\")\n",
    "        break\n",
    "      # this is the size of the chunk, incidentally its inclusive\n",
    "      cbSize = unpack('<I', read)[0]\n",
    "      # so to read the rest, we subtract four\n",
    "      chunk = BytesIO(f.read(cbSize - 4))\n",
    "      # wow such bit op\n",
    "      presenceBitArray = bytearray(chunk.read(int(math.ceil(OAB_cAtts / 8.0))))\n",
    "      indices = [i for i in range(OAB_cAtts) if (presenceBitArray[i // 8] >> (7 - (i % 8))) & 1 == 1]\n",
    "      #print(\"\\n----------------------------------------\")\n",
    "      # print \"Chunk Size: \", cbSize\n",
    "\n",
    "      def read_str():\n",
    "        # strings in the OAB format are null-terminated\n",
    "        buf = b\"\"\n",
    "        while True:\n",
    "          n = chunk.read(1)\n",
    "          if n == b\"\\0\" or n == b\"\":\n",
    "            break\n",
    "          buf += n\n",
    "        return buf.decode('utf-8') # problem here\n",
    "        # return unicode(buf, errors=\"ignore\")\n",
    "\n",
    "      def read_int():\n",
    "        # integers are cool aren't they\n",
    "        byte_count = unpack('<B', chunk.read(1))[0]\n",
    "        if 0x81 <= byte_count <= 0x84:\n",
    "          byte_count = unpack('<I', (chunk.read(byte_count - 0x80) + b\"\\0\\0\\0\")[0:4])[0]\n",
    "        else:\n",
    "          if byte_count > 127:\n",
    "            return -1\n",
    "        return byte_count\n",
    "\n",
    "      user = {}\n",
    "\n",
    "      # Start building a user by manually scanning the file for key:value pairs\n",
    "      for i in indices:\n",
    "        PropID = hexify(OAB_Atts[i])\n",
    "        if PropID not in PidTagSchema:\n",
    "          continue\n",
    "          raise ValueError(\"This property id (\" + PropID + \") does not exist in the schema\")\n",
    "\n",
    "        (Name, Type) = PidTagSchema[PropID]\n",
    "\n",
    "        if Type == \"PtypString8\" or Type == \"PtypString\":\n",
    "          val = read_str()\n",
    "          user[Name] = val\n",
    "          # print(Name, val)\n",
    "        elif Type == \"PtypBoolean\":\n",
    "          val = unpack('<?', chunk.read(1))[0]\n",
    "          user[Name] = val\n",
    "          # print (Name, val)\n",
    "        elif Type == \"PtypInteger32\":\n",
    "          val = read_int()\n",
    "          user[Name] = val\n",
    "          # print(Name, val)\n",
    "        elif Type == \"PtypBinary\":\n",
    "          bin = chunk.read(read_int())\n",
    "          user[Name] = binascii.b2a_hex(bin)\n",
    "          # print(Name, len(bin), binascii.b2a_hex(bin))\n",
    "        elif Type == \"PtypMultipleString\" or Type == \"PtypMultipleString8\":\n",
    "          byte_count = read_int()\n",
    "          # print (Name, byte_count)\n",
    "          arr = []\n",
    "          for i in range(byte_count):\n",
    "            val = read_str()\n",
    "            arr.append(val)\n",
    "            # print(i, \"\\t\", val)\n",
    "          user[Name] = arr\n",
    "        elif Type == \"PtypMultipleInteger32\":\n",
    "          byte_count = read_int()\n",
    "          # print(Name, byte_count)\n",
    "          arr = []\n",
    "          for i in range(byte_count):\n",
    "            val = read_int()\n",
    "            if Name == \"OfflineAddressBookTruncatedProperties\":\n",
    "              val = hexify(val)\n",
    "              if val in PidTagSchema:\n",
    "                val = PidTagSchema[val][0]\n",
    "            arr.append(val)\n",
    "            # print(i, \"\\t\", val)\n",
    "          user[Name] = arr\n",
    "\n",
    "        elif Type == \"PtypMultipleBinary\":\n",
    "          byte_count = read_int()\n",
    "          # print(Name, byte_count)\n",
    "          arr = []\n",
    "          for i in range(byte_count):\n",
    "            bin_len = read_int()\n",
    "            bin = chunk.read(bin_len)\n",
    "            arr.append(binascii.b2a_hex(bin))\n",
    "            #print(i, \"\\t\", bin_len, binascii.b2a_hex(bin))\n",
    "          user[Name] = arr\n",
    "        else:\n",
    "          raise \"Unknown property type (\" + Type + \")\"\n",
    "        # This is the previous script default behavior. I've left it here in case someone actually makes it work.\n",
    "        if Name == \"DisplayName\":\n",
    "          # check if name matches regex [A-Za-z with space] ([0-9]) get match of the first and second part assign to varibles\n",
    "          a = re.match(r\"^([A-Za-z ]+) (\\([0-9]+\\))$\", val)\n",
    "          if a:\n",
    "            d[a.group(1)] = a.group(2)[1:-1]\n",
    "      remains = chunk.read()\n",
    "      users.append(user)\n",
    "    except KeyboardInterrupt:\n",
    "      exit(1)\n",
    "    except error:\n",
    "      # Yeah, I know it sucks, but again, I've got no time of checking what magicky migicky the bits are doing.\n",
    "      # Log and move on.\n",
    "      if user[\"SmtpAddress\"] in seen_emails:\n",
    "          print(f\"Duplicate {user[\"SmtpAddress\"]} found. Stopping now\")\n",
    "          break\n",
    "      broken_users.append(user)\n",
    "      seen_emails.add(user[\"SmtpAddress\"])\n",
    "      error_count += 1\n",
    "      pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78083a-3a1f-49ab-ab23-37779cc2ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "# Old writing behavior. I've never gotten it to work, since Json doesn't accept bytes\n",
    "#json_out = open('test.json', 'w')\n",
    "#json_out.write(json.dumps(d, indent=4))\n",
    "#json_out.close()\n",
    "\n",
    "\n",
    "# Cache the files if you want\n",
    "with open(\"broken_users.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "  for user in broken_users:\n",
    "    file.write(str(user) + \"\\n\")\n",
    "    \n",
    "with open(\"users.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "  for user in users:\n",
    "    file.write(str(user) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab41ef80-baa0-4923-885a-ee9b6c3e565c",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "Here we convert our raw JSON into a pretty CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672e829-b7bf-4a14-a873-f272bd37b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "data = broken_users + users\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4c06f-7d5e-46ba-900e-152b064702dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the Dataframe! You can edit it, remove columns, search and do other DS stuff to it!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d84663-7ef2-4aa0-a8bf-0f74c344004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The money: output it into a CSV.\n",
    "df.to_csv(\"converted.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
